{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CharacterModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k8WzJarn7Nw"
      },
      "source": [
        "# Character model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAcVDjuVoA3P",
        "outputId": "94430f01-6939-44af-ba1f-a669079ea8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lzxu4roB48"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Activation\n",
        "from keras.activations import softmax as Softmax\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EbbG_ArR2gm",
        "outputId": "fd87961d-f0ec-4f28-cda1-b2853e94d63a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "with open(\"/content/drive/My Drive/DeepLearning/mar.txt\", \"r\") as a:\n",
        "  print (a.readline())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tजा.\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #3138228 (sabretou)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ1qgtpvSAva",
        "outputId": "a10ab504-d62b-4086-cb20-141ae075ee75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# clean unwanted data\n",
        "sep = '\\tCC'\n",
        "with open(\"/content/drive/My Drive/DeepLearning/mar.txt\") as file_in:\n",
        "    lines = []\n",
        "    for line in file_in:\n",
        "        res = line.split(sep,1)[0]\n",
        "        #print(res)\n",
        "        lines.append(res + \"\\n\")\n",
        "f = open('/content/drive/My Drive/DeepLearning/mar_1.txt','w')\n",
        "for line in lines:\n",
        "  f.write(line)\n",
        "f.close()\n",
        "\n",
        "# modified text file\n",
        "with open(\"/content/drive/My Drive/DeepLearning/mar_1.txt\", \"r\") as a:\n",
        "  print (a.readline())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tजा.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4N95xweoM_v"
      },
      "source": [
        "BATCH_SIZE = 32  # Batch size for training\n",
        "NUM_SAMPLES = 10000\n",
        "EPOCHS = 50\n",
        "OPTIMIZER = \"rmsprop\"\n",
        "EMBED_DIM = 300\n",
        "HIDDEN_DIM = 256\n",
        "DATA_PATH = '/content/drive/My Drive/DeepLearning/mar_1.txt'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdA-Ed2JoUCS"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gti68jWnoVk3"
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between words and punctation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    #w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sequence\n",
        "    # so that the model know when to start and stop predicting\n",
        "    w = \"\\t \" + w + \" \\n\"\n",
        "    return w"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvQKfWk9oYa2"
      },
      "source": [
        "def loadGloveModel(gloveFile):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(gloveFile, 'r', encoding = \"utf8\")\n",
        "    model = {}\n",
        "    for line in f:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
        "        model[word] = embedding\n",
        "    print(\"Done.\", len(model), \" words loaded!\")\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnWph39podss"
      },
      "source": [
        "def load_embedding(filename):\n",
        "    print(\"Loading Glove Model\")\n",
        "    embedding_model = {}\n",
        "    f = open(filename,'r', encoding=\"utf8\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = ''.join(values[:-300])\n",
        "        coefs = np.array(values[-300:], dtype='float32')\n",
        "        embedding_model[word] = coefs\n",
        "    print(\"Done.\", len(embedding_model), \" words loaded!\")\n",
        "    f.close()\n",
        "    return embedding_model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72nctSo3oh2x",
        "outputId": "d024b4e0-d1dd-4bd8-abca-9d10a62f222d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "eng_embedding= loadGloveModel(\"/content/drive/My Drive/DeepLearning/glove.6B.300d.txt\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "Done. 400000  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ze6nsFsouSg"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "target_chars = set()\n",
        "\n",
        "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "    for line in lines[:NUM_SAMPLES]:\n",
        "        input_text, target_text = line.split('\\t')\n",
        "        input_text = preprocess_sentence(input_text)\n",
        "        target_text = preprocess_sentence(target_text)\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(target_text)\n",
        "        target_chars.update(list(target_text))\n",
        "\n",
        "target_chars = sorted(list(target_chars))\n",
        "#print(target_text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMOrNiD6oufD"
      },
      "source": [
        "# get attributes from data\n",
        "max_input_seqlen = max([len(txt.split()) for txt in input_texts])\n",
        "max_target_seqlen = max([len(txt) for txt in target_texts])\n",
        "target_token_size = len(target_chars)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrqsnADFouii"
      },
      "source": [
        "# get decoder data\n",
        "targchars2idx = dict([(char, i) for i, char in enumerate(target_chars)])\n",
        "idx2targchars = dict((i, char) for char, i in targchars2idx.items())\n",
        "decoder_data = np.zeros(\n",
        "    shape=(NUM_SAMPLES, max_target_seqlen, target_token_size))\n",
        "decoder_target_data = np.zeros(\n",
        "    shape=(NUM_SAMPLES, max_target_seqlen, target_token_size))\n",
        "\n",
        "for textIdx, text in enumerate(target_texts):\n",
        "    for idx, char in enumerate(text):\n",
        "        c2idx = targchars2idx[char]\n",
        "        decoder_data[textIdx, idx, c2idx] = 1\n",
        "        if idx > 0:\n",
        "            decoder_target_data[textIdx, idx - 1, c2idx] = 1\n",
        "#print(targchars2idx[\"\\t\"])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rMI300mouX8"
      },
      "source": [
        "# get encoder data\n",
        "encoder_data = []\n",
        "for text in input_texts:\n",
        "    tmp = []\n",
        "    for word in text.split():\n",
        "        embed = np.random.randn(EMBED_DIM)\n",
        "        if word in eng_embedding:\n",
        "            embed = eng_embedding[word]\n",
        "        tmp.append(embed)\n",
        "    encoder_data.append(tmp)\n",
        "encoder_data = pad_sequences(encoder_data, max_input_seqlen, padding=\"post\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoNrx9LlouIr",
        "outputId": "d45b756e-1c1b-4a5e-9c70-df0d5edb0d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "decoder_data.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 40, 74)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhwNotDUp0Ko",
        "outputId": "3d1055bb-e7f3-4563-9eb8-c5a3613e230b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "decoder_target_data.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 40, 74)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fKDbUmcp2_s",
        "outputId": "9a5474d0-c836-4a26-bc87-be26a81be935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "encoder_data.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 7, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_uAbU8Kp5HR"
      },
      "source": [
        "# construct model\n",
        "encoder_inputs = Input(shape=(max_input_seqlen, EMBED_DIM))\n",
        "encoder_lstm = LSTM(HIDDEN_DIM, return_state=True, name=\"encoder_lstm\")\n",
        "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, target_token_size))\n",
        "decoder_lstm = LSTM(HIDDEN_DIM, return_sequences=True,\n",
        "                    return_state=True, name=\"decoder_lstm\")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "    decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(\n",
        "    target_token_size, activation=\"softmax\", name=\"decoder_dense\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cYeWiQXp7CB",
        "outputId": "d0386546-98c0-465d-8162-c0ca56753d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# define training model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer=OPTIMIZER,\n",
        "              loss='categorical_crossentropy', metrics=[\"acc\"])\n",
        "print(model.summary())\n",
        "filename = 'seq2seq_keras.h5'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filename, verbose=1, save_best_only=True, mode='min')\n",
        "# checkpoint = ModelCheckpoint(filename, verbose=1, mode='min')\n",
        "model = model.fit([encoder_data, decoder_data], decoder_target_data,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS, validation_split=0.2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 7, 300)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 74)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 256), (None, 570368      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  338944      input_2[0][0]                    \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 74)     19018       decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 928,330\n",
            "Trainable params: 928,330\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "250/250 [==============================] - 3s 11ms/step - loss: 1.1038 - acc: 0.1848 - val_loss: 1.0495 - val_acc: 0.2526\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.7950 - acc: 0.2528 - val_loss: 0.9361 - val_acc: 0.2788\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.7095 - acc: 0.2691 - val_loss: 0.8599 - val_acc: 0.2917\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6500 - acc: 0.2824 - val_loss: 0.8307 - val_acc: 0.3002\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5998 - acc: 0.2958 - val_loss: 0.8020 - val_acc: 0.3087\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5569 - acc: 0.3070 - val_loss: 0.7639 - val_acc: 0.3185\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.5192 - acc: 0.3167 - val_loss: 0.7414 - val_acc: 0.3259\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.4844 - acc: 0.3264 - val_loss: 0.7366 - val_acc: 0.3275\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.4522 - acc: 0.3354 - val_loss: 0.7303 - val_acc: 0.3320\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.4232 - acc: 0.3437 - val_loss: 0.7334 - val_acc: 0.3323\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3960 - acc: 0.3508 - val_loss: 0.7444 - val_acc: 0.3329\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3704 - acc: 0.3584 - val_loss: 0.7345 - val_acc: 0.3353\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3460 - acc: 0.3650 - val_loss: 0.7592 - val_acc: 0.3353\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3238 - acc: 0.3712 - val_loss: 0.7640 - val_acc: 0.3353\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.3026 - acc: 0.3774 - val_loss: 0.7704 - val_acc: 0.3354\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2833 - acc: 0.3826 - val_loss: 0.7893 - val_acc: 0.3346\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2647 - acc: 0.3882 - val_loss: 0.7928 - val_acc: 0.3350\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2470 - acc: 0.3935 - val_loss: 0.8152 - val_acc: 0.3340\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2316 - acc: 0.3978 - val_loss: 0.8240 - val_acc: 0.3348\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2166 - acc: 0.4017 - val_loss: 0.8434 - val_acc: 0.3331\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.2033 - acc: 0.4056 - val_loss: 0.8710 - val_acc: 0.3347\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.1903 - acc: 0.4093 - val_loss: 0.8671 - val_acc: 0.3341\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.1780 - acc: 0.4133 - val_loss: 0.8916 - val_acc: 0.3330\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.1674 - acc: 0.4159 - val_loss: 0.9094 - val_acc: 0.3326\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.1567 - acc: 0.4190 - val_loss: 0.9231 - val_acc: 0.3338\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.1477 - acc: 0.4216 - val_loss: 0.9408 - val_acc: 0.3327\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.1392 - acc: 0.4239 - val_loss: 0.9585 - val_acc: 0.3339\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.1313 - acc: 0.4260 - val_loss: 0.9814 - val_acc: 0.3319\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.1238 - acc: 0.4284 - val_loss: 0.9966 - val_acc: 0.3317\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.1172 - acc: 0.4298 - val_loss: 1.0180 - val_acc: 0.3311\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.1113 - acc: 0.4315 - val_loss: 1.0118 - val_acc: 0.3308\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.1046 - acc: 0.4335 - val_loss: 1.0536 - val_acc: 0.3305\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0999 - acc: 0.4344 - val_loss: 1.0475 - val_acc: 0.3312\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0946 - acc: 0.4359 - val_loss: 1.0734 - val_acc: 0.3301\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0903 - acc: 0.4372 - val_loss: 1.1059 - val_acc: 0.3297\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0863 - acc: 0.4381 - val_loss: 1.0825 - val_acc: 0.3313\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0825 - acc: 0.4392 - val_loss: 1.1110 - val_acc: 0.3297\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0792 - acc: 0.4400 - val_loss: 1.1317 - val_acc: 0.3299\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0757 - acc: 0.4411 - val_loss: 1.1399 - val_acc: 0.3298\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0732 - acc: 0.4415 - val_loss: 1.1585 - val_acc: 0.3299\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0706 - acc: 0.4421 - val_loss: 1.1515 - val_acc: 0.3306\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0673 - acc: 0.4432 - val_loss: 1.1768 - val_acc: 0.3292\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0648 - acc: 0.4439 - val_loss: 1.1696 - val_acc: 0.3284\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0628 - acc: 0.4445 - val_loss: 1.1689 - val_acc: 0.3304\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0615 - acc: 0.4445 - val_loss: 1.1982 - val_acc: 0.3291\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0597 - acc: 0.4452 - val_loss: 1.2099 - val_acc: 0.3299\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0578 - acc: 0.4455 - val_loss: 1.2239 - val_acc: 0.3302\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0563 - acc: 0.4460 - val_loss: 1.2319 - val_acc: 0.3283\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0550 - acc: 0.4462 - val_loss: 1.2295 - val_acc: 0.3302\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0535 - acc: 0.4466 - val_loss: 1.2456 - val_acc: 0.3297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLWyH4fbqECh"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(HIDDEN_DIM,))\n",
        "decoder_state_input_c = Input(shape=(HIDDEN_DIM,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# decoder_outputs = (BATCH_SIZE, seqlen, HIDDEN_DIM)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# decoder_outputs = (BATCH_SIZE, seqlen, target_token_size)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jis3jDln5Jsi"
      },
      "source": [
        "def decode(input_seq):\n",
        "    states = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1, target_token_size))\n",
        "    target_seq[0, 0, targchars2idx['\\t']] = 1.0\n",
        "    stop_condition = False\n",
        "    prediction = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states)\n",
        "        sampled_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = idx2targchars[sampled_token_idx]\n",
        "        prediction += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or len(prediction) > max_target_seqlen):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1, 1, target_token_size))\n",
        "        target_seq[0, 0, sampled_token_idx] = 1.0\n",
        "        states = [h, c]\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_r6U6fQ5Mec",
        "outputId": "fee75118-04c2-4b29-be76-9c5590879c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "actual, predicted = list(), list()\n",
        "\n",
        "for index in [1900, 5534, 7467, 1258, 4500, 1345, 7863, 7688, 6782]: # considered random index\n",
        "    input_seq = encoder_data[index]\n",
        "    input_seq = np.expand_dims(input_seq, axis=0)\n",
        "    actual.append(target_texts[index].split())\n",
        "    prediction = decode(input_seq)\n",
        "    predicted.append(prediction.split())\n",
        "    print('-')\n",
        "    print(\"Input sentence:\",input_texts[index])\n",
        "    print(\"Translation: \", prediction)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: \t you will die . \n",
            "\n",
            "Translation:   मराल तमही . \n",
            "\n",
            "-\n",
            "Input sentence: \t give me my money . \n",
            "\n",
            "Translation:   मला माझ पस द . \n",
            "\n",
            "-\n",
            "Input sentence: \t i tried to forget . \n",
            "\n",
            "Translation:   मी पिर झाला . \n",
            "\n",
            "-\n",
            "Input sentence: \t what's that ? \n",
            "\n",
            "Translation:   त काय आह ? \n",
            "\n",
            "-\n",
            "Input sentence: \t i'm your friend . \n",
            "\n",
            "Translation:   मी तझी मतरिण आह . \n",
            "\n",
            "-\n",
            "Input sentence: \t come help me . \n",
            "\n",
            "Translation:   या माझी मदत करा . \n",
            "\n",
            "-\n",
            "Input sentence: \t she is her friend . \n",
            "\n",
            "Translation:   ती तिची मतरिण आह . \n",
            "\n",
            "-\n",
            "Input sentence: \t it was quite cold . \n",
            "\n",
            "Translation:   बर‍यापकी थड होत . \n",
            "\n",
            "-\n",
            "Input sentence: \t why didn't i die ? \n",
            "\n",
            "Translation:   मी का नाही मलो ? \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2isp4X-5mNW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}