{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgS4En4ZzNmZ"
      },
      "source": [
        "# Word Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMSOD3SK3UqY",
        "outputId": "4046c7d8-aaed-4106-db2b-5932d2ccd87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnFXFA_yl2-i"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Activation\n",
        "from keras.activations import softmax as Softmax\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc2AIblbK8rb",
        "outputId": "f63ff1b4-0a51-4594-fc7c-ed3fb46fe58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# clean unwanted data\n",
        "sep = '\\tCC'\n",
        "with open(\"/content/drive/My Drive/DeepLearning/mar.txt\") as file_in:\n",
        "    lines = []\n",
        "    for line in file_in:\n",
        "        res = line.split(sep,1)[0]\n",
        "        #print(res)\n",
        "        lines.append(res + \"\\n\")\n",
        "f = open('/content/drive/My Drive/DeepLearning/mar_1.txt','w')\n",
        "for line in lines:\n",
        "  f.write(line)\n",
        "f.close()\n",
        "\n",
        "# modified text file\n",
        "with open(\"/content/drive/My Drive/DeepLearning/mar_1.txt\", \"r\") as a:\n",
        "  print (a.readline())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go.\tजा.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbzMRx2fmGws"
      },
      "source": [
        "BATCH_SIZE = 32  # Batch size for training\n",
        "NUM_SAMPLES = 10000\n",
        "EPOCHS = 50\n",
        "OPTIMIZER = \"rmsprop\"\n",
        "EMBED_DIM = 300\n",
        "HIDDEN_DIM = 50\n",
        "DATA_PATH = '/content/drive/My Drive/DeepLearning/mar_1.txt'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-PuTtkamMj-"
      },
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awmG6tGmmRB1"
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between words and punctation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    #w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.rstrip().strip()\n",
        "\n",
        "    # adding a start and an end token to the sequence\n",
        "    # so that the model know when to start and stop predicting\n",
        "    w = \"\\t \" + w + \" \\n\"\n",
        "    return w"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1T4byQPK8rk"
      },
      "source": [
        "def loadGloveModel(gloveFile):\n",
        "    print(\"Loading Glove Model\")\n",
        "    f = open(gloveFile, 'r', encoding = \"utf8\")\n",
        "    model = {}\n",
        "    for line in f:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
        "        model[word] = embedding\n",
        "    print(\"Done.\", len(model), \" words loaded!\")\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fabhddzK8rm"
      },
      "source": [
        "def load_embedding(filename):\n",
        "    print(\"Loading Glove Model\")\n",
        "    embedding_model = {}\n",
        "    f = open(filename,'r', encoding=\"utf8\")\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = ''.join(values[:-300])\n",
        "        coefs = np.array(values[-300:], dtype='float32')\n",
        "        embedding_model[word] = coefs\n",
        "    print(\"Done.\", len(embedding_model), \" words loaded!\")\n",
        "    f.close()\n",
        "    return embedding_model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUl4RiiRtclu",
        "outputId": "655093ec-3071-4921-bf32-000e7a0b0d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "mar_embedding = load_embedding('/content/drive/My Drive/DeepLearning/indicnlp.v1.mr.vec')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "Done. 533456  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCSu2x19K8rq",
        "outputId": "366e4ff8-e1ec-4d20-f853-e8e39559a654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "eng_embedding= loadGloveModel(\"/content/drive/My Drive/DeepLearning/glove.6B.300d.txt\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n",
            "Done. 400000  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b38exLa3yW7C"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "target_words = set()\n",
        "\n",
        "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "    for line in lines[:NUM_SAMPLES]:\n",
        "        input_text, target_text = line.split('\\t')\n",
        "        # print(target_text) \n",
        "        input_text = preprocess_sentence(input_text)\n",
        "        target_text = preprocess_sentence(target_text)\n",
        "        input_texts.append(input_text)\n",
        "        target_texts.append(target_text)\n",
        "        #target_words.update(list(target_words))\n",
        "        target_words.update(target_text.split())\n",
        "\n",
        "target_words = sorted(list(target_words))\n",
        "#print(target_text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbsAnd7zyXeP"
      },
      "source": [
        "max_input_seqlen = max([len(txt.split()) for txt in input_texts])\n",
        "#print(max_input_seqlen)\n",
        "max_target_seqlen = max([len(txt.split()) for txt in target_texts])\n",
        "#print(max_target_seqlen)\n",
        "target_vocab_size = len(target_words) + 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8QkrLIMycmU"
      },
      "source": [
        "# get decoder input data\n",
        "decoder_data = []\n",
        "for text in target_texts:\n",
        "    tmp = []\n",
        "    for word in text.split():\n",
        "        embed = np.random.randn(EMBED_DIM)# output is an array\n",
        "        if word in mar_embedding:\n",
        "            embed = mar_embedding[word]\n",
        "        tmp.append(embed)\n",
        "    decoder_data.append(tmp)# list\n",
        "#print(type(decoder_data))\n",
        "decoder_data = pad_sequences(decoder_data, max_target_seqlen, padding=\"post\")\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHLcmKSsyfEd"
      },
      "source": [
        "# get decoder target data\n",
        "targword2idx = dict([(word, i + 1) for i, word in enumerate(target_words)])\n",
        "idx2targword = dict((i, word) for word, i in targword2idx.items())\n",
        "decoder_target_data = []\n",
        "for text in target_texts:\n",
        "    tmp = []\n",
        "    for idx, word in enumerate(text.split()):\n",
        "        if idx > 0:\n",
        "            tmp.append(targword2idx[word])\n",
        "    decoder_target_data.append(tmp)\n",
        "decoder_target_data = pad_sequences(\n",
        "    decoder_target_data, max_target_seqlen, padding=\"post\")\n",
        "decoder_target_data = to_categorical(decoder_target_data)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUiCFnvLyiA7"
      },
      "source": [
        "# get encoder data\n",
        "encoder_data = []\n",
        "for text in input_texts:\n",
        "    tmp = []\n",
        "    for word in text.split():\n",
        "        embed = np.random.randn(EMBED_DIM)\n",
        "        if word in eng_embedding:\n",
        "            embed = eng_embedding[word]\n",
        "        tmp.append(embed)\n",
        "    encoder_data.append(tmp)\n",
        "encoder_data = pad_sequences(encoder_data, max_input_seqlen, padding=\"post\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieMSWUfWyjCa",
        "outputId": "a4dac23d-e2fa-4834-e209-93124256a5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "encoder_data.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 7, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q623n_kKylJy",
        "outputId": "c580357b-230e-4a18-955b-15c1b7746574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "decoder_data.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 12, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ipgzf4Dym10",
        "outputId": "e97cb2d8-2e9f-46ab-c9fb-96bae2f604fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "decoder_target_data.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 12, 3475)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDLIJJNSyuQC"
      },
      "source": [
        "# construct model\n",
        "encoder_inputs = Input(shape=(max_input_seqlen, EMBED_DIM))\n",
        "encoder_lstm = LSTM(HIDDEN_DIM, return_state=True, name=\"encoder_lstm\")\n",
        "_, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None,EMBED_DIM))\n",
        "#decoder_inputs = Input(shape=(max_target_seqlen, EMBED_DIM))\n",
        "decoder_lstm = LSTM(HIDDEN_DIM, return_sequences=True,\n",
        "                    return_state=True, name=\"decoder_lstm\")\n",
        "decoder_outputs, _, _ = decoder_lstm(\n",
        "    decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(\n",
        "    target_vocab_size, activation=\"softmax\", name=\"decoder_dense\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8EhIVL0yu7I",
        "outputId": "11ce7cb5-661a-4eb0-be89-81c594e53353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "#define training model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer=OPTIMIZER,\n",
        "              loss='categorical_crossentropy', metrics=[\"acc\"])\n",
        "print(model.summary())\n",
        "filename = 'seq2seq_keras.h5'\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filename, verbose=1, save_best_only=True, mode='min')\n",
        "# checkpoint = ModelCheckpoint(filename, verbose=1, mode='min')\n",
        "model.fit([encoder_data, decoder_data], decoder_target_data,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,  \n",
        "          validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 7, 300)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 300)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 50), (None,  70200       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 50), ( 70200       input_2[0][0]                    \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 3475)   177225      decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 317,625\n",
            "Trainable params: 317,625\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "250/250 [==============================] - 21s 84ms/step - loss: 2.3882 - acc: 0.7288 - val_loss: 1.8698 - val_acc: 0.7088\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 1.4576 - acc: 0.7573 - val_loss: 1.8718 - val_acc: 0.7125\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 1.4179 - acc: 0.7627 - val_loss: 1.8693 - val_acc: 0.7144\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.3879 - acc: 0.7677 - val_loss: 1.8506 - val_acc: 0.7163\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.3562 - acc: 0.7738 - val_loss: 1.8409 - val_acc: 0.7187\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 1.3186 - acc: 0.7800 - val_loss: 1.8480 - val_acc: 0.7164\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 1.2833 - acc: 0.7872 - val_loss: 1.8524 - val_acc: 0.7246\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 1.2495 - acc: 0.7934 - val_loss: 1.8332 - val_acc: 0.7231\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.2196 - acc: 0.7987 - val_loss: 1.8621 - val_acc: 0.7260\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 1.1927 - acc: 0.8026 - val_loss: 1.8314 - val_acc: 0.7247\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.1710 - acc: 0.8062 - val_loss: 1.8217 - val_acc: 0.7234\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.1515 - acc: 0.8096 - val_loss: 1.8064 - val_acc: 0.7234\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 1.1335 - acc: 0.8113 - val_loss: 1.8132 - val_acc: 0.7255\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 1.1158 - acc: 0.8138 - val_loss: 1.8352 - val_acc: 0.7268\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 1.1015 - acc: 0.8162 - val_loss: 1.8675 - val_acc: 0.7267\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.0857 - acc: 0.8184 - val_loss: 1.8511 - val_acc: 0.7124\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.0703 - acc: 0.8211 - val_loss: 1.8473 - val_acc: 0.7266\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 1.0562 - acc: 0.8233 - val_loss: 1.8542 - val_acc: 0.7265\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 1.0420 - acc: 0.8253 - val_loss: 1.8807 - val_acc: 0.7274\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 1.0290 - acc: 0.8263 - val_loss: 1.8658 - val_acc: 0.7278\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 1.0151 - acc: 0.8293 - val_loss: 1.9046 - val_acc: 0.7295\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 1.0004 - acc: 0.8301 - val_loss: 1.9139 - val_acc: 0.7281\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.9880 - acc: 0.8330 - val_loss: 1.9519 - val_acc: 0.7298\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.9772 - acc: 0.8343 - val_loss: 1.8931 - val_acc: 0.7270\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.9658 - acc: 0.8368 - val_loss: 1.9069 - val_acc: 0.7285\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 0.9549 - acc: 0.8387 - val_loss: 1.9313 - val_acc: 0.7302\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.9451 - acc: 0.8403 - val_loss: 1.9169 - val_acc: 0.7276\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.9352 - acc: 0.8420 - val_loss: 1.9415 - val_acc: 0.7287\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.9268 - acc: 0.8438 - val_loss: 1.9661 - val_acc: 0.7301\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.9190 - acc: 0.8450 - val_loss: 1.9726 - val_acc: 0.7305\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.9100 - acc: 0.8465 - val_loss: 1.9672 - val_acc: 0.7275\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 0.9028 - acc: 0.8483 - val_loss: 1.9977 - val_acc: 0.7284\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.8960 - acc: 0.8496 - val_loss: 2.0014 - val_acc: 0.7287\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 0.8879 - acc: 0.8514 - val_loss: 2.0290 - val_acc: 0.7285\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.8819 - acc: 0.8528 - val_loss: 2.0272 - val_acc: 0.7287\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.8778 - acc: 0.8543 - val_loss: 2.0295 - val_acc: 0.7277\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.8741 - acc: 0.8552 - val_loss: 2.0388 - val_acc: 0.7295\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.8706 - acc: 0.8564 - val_loss: 2.0653 - val_acc: 0.7288\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.8684 - acc: 0.8575 - val_loss: 2.0391 - val_acc: 0.7280\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.8637 - acc: 0.8591 - val_loss: 2.1044 - val_acc: 0.7288\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 21s 85ms/step - loss: 0.8607 - acc: 0.8602 - val_loss: 2.0504 - val_acc: 0.7266\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.8522 - acc: 0.8619 - val_loss: 2.0706 - val_acc: 0.7283\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.8459 - acc: 0.8625 - val_loss: 2.0587 - val_acc: 0.7264\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.8420 - acc: 0.8637 - val_loss: 2.0510 - val_acc: 0.7247\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 21s 84ms/step - loss: 0.8370 - acc: 0.8653 - val_loss: 2.0799 - val_acc: 0.7280\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.8333 - acc: 0.8661 - val_loss: 2.0863 - val_acc: 0.7227\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 21s 83ms/step - loss: 0.8295 - acc: 0.8671 - val_loss: 2.1336 - val_acc: 0.7276\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 0.8262 - acc: 0.8682 - val_loss: 2.1273 - val_acc: 0.7275\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 20s 82ms/step - loss: 0.8237 - acc: 0.8688 - val_loss: 2.1303 - val_acc: 0.7258\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 21s 82ms/step - loss: 0.8196 - acc: 0.8703 - val_loss: 2.1233 - val_acc: 0.7259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9a1d72be10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqceS8EXy8fk"
      },
      "source": [
        "# create inference model\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(HIDDEN_DIM,))\n",
        "decoder_state_input_c = Input(shape=(HIDDEN_DIM,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# decoder_outputs = (BATCH_SIZE, seqlen, HIDDEN_DIM)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "# decoder_outputs = (BATCH_SIZE, seqlen, target_token_size)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfRMJisIkBwB"
      },
      "source": [
        "def decode(input_seq):\n",
        "    states = encoder_model.predict(input_seq)\n",
        "    target_seq = np.random.randn(EMBED_DIM)\n",
        "    target_seq = [[target_seq]]\n",
        "    stop_condition = False\n",
        "    prediction = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states)\n",
        "        sampled_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = idx2targword[sampled_token_idx]\n",
        "        prediction += sampled_word + \" \"\n",
        "\n",
        "        if (sampled_word == '\\n' or len(prediction) > max_target_seqlen):\n",
        "            stop_condition = True\n",
        "\n",
        "        if sampled_word in mar_embedding:\n",
        "            target_seq = mar_embedding[sampled_word]\n",
        "        else:\n",
        "            target_seq = np.random.randn(EMBED_DIM)\n",
        "        target_seq = [[target_seq]]\n",
        "        states = [h, c]\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoUrOGXizALq",
        "outputId": "65ec0f9e-a4e8-49bf-a784-90c9f47c1baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "actual, predicted = list(), list()\n",
        "\n",
        "for index in [1900, 5534, 7467, 1258, 4500, 1345, 7863, 7688, 6782]: # considered random index\n",
        "    input_seq = encoder_data[index]\n",
        "    input_seq = np.expand_dims(input_seq, axis=0)\n",
        "    actual.append(target_texts[index].split())\n",
        "    prediction = decode(input_seq)\n",
        "    predicted.append(prediction.split())\n",
        "    print('-')\n",
        "    print(\"Input sentence: \", input_texts[index])\n",
        "    print(\"Translation: \", prediction)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence:  \t you will die . \n",
            "\n",
            "Translation:  \t मरशील . \n",
            "\n",
            "-\n",
            "Input sentence:  \t give me my money . \n",
            "\n",
            "Translation:  \t मला माझ पस द . \n",
            "\n",
            "-\n",
            "Input sentence:  \t i tried to forget . \n",
            "\n",
            "Translation:  \t मी विसरायचा परयतन कला . \n",
            "\n",
            "-\n",
            "Input sentence:  \t what's that ? \n",
            "\n",
            "Translation:  \t त काय आह ? \n",
            "\n",
            "-\n",
            "Input sentence:  \t i'm your friend . \n",
            "\n",
            "Translation:  \t मी तझी मतरिण आह . \n",
            "\n",
            "-\n",
            "Input sentence:  \t come help me . \n",
            "\n",
            "Translation:  \t य माझी मदत कर . \n",
            "\n",
            "-\n",
            "Input sentence:  \t she is her friend . \n",
            "\n",
            "Translation:  \t ती तयाची मतरिण आह . \n",
            "\n",
            "-\n",
            "Input sentence:  \t it was quite cold . \n",
            "\n",
            "Translation:  \t बर‍यापकी थड होता . \n",
            "\n",
            "-\n",
            "Input sentence:  \t why didn't i die ? \n",
            "\n",
            "Translation:  \t मी का नाही मलो ? \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAd74WCtSYMj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}